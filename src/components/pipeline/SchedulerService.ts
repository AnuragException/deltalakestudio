
import { ScheduleConfig } from './types';

/**
 * Generates Airflow DAG code for scheduling pipeline execution
 * @param pipelineName Name of the pipeline to schedule
 * @param config Schedule configuration
 * @returns Generated Airflow DAG code
 */
export const generateSchedulerCode = (
  pipelineName: string,
  config: ScheduleConfig
): string => {
  // Generate cron expression based on frequency
  let cronExpression = config.cronExpression || '';
  
  if (!cronExpression) {
    switch (config.frequency) {
      case 'once':
        cronExpression = ''; // One-time execution doesn't use cron
        break;
      case 'hourly':
        cronExpression = '0 * * * *';
        break;
      case 'daily':
        cronExpression = '0 0 * * *';
        break;
      case 'weekly':
        cronExpression = '0 0 * * 0'; // Sunday at midnight
        break;
      case 'monthly':
        cronExpression = '0 0 1 * *'; // 1st of each month
        break;
      case 'custom':
        cronExpression = '0 0 * * *'; // Default to daily if custom but no expression provided
        break;
    }
  }
  
  // Create Airflow DAG code
  let code = `# Airflow DAG for ${pipelineName}\n`;
  code += `# Generated by Pipeline Designer\n\n`;
  
  // Import statements
  code += `from datetime import datetime, timedelta\n`;
  code += `from airflow import DAG\n`;
  code += `from airflow.providers.databricks.operators.databricks import DatabricksRunNowOperator\n`;
  code += `from airflow.operators.python import PythonOperator\n\n`;
  
  // Default arguments
  code += `# Default arguments for the DAG\n`;
  code += `default_args = {\n`;
  code += `    'owner': 'airflow',\n`;
  code += `    'depends_on_past': False,\n`;
  code += `    'start_date': datetime(${new Date().getFullYear()}, ${new Date().getMonth() + 1}, ${new Date().getDate()}),\n`;
  code += `    'email_on_failure': True,\n`;
  code += `    'email_on_retry': False,\n`;
  code += `    'retries': 1,\n`;
  code += `    'retry_delay': timedelta(minutes=5),\n`;
  code += `}\n\n`;
  
  // Define the DAG
  code += `# Define the DAG\n`;
  
  if (cronExpression) {
    code += `dag = DAG(\n`;
    code += `    '${pipelineName.replace(/\s+/g, '_').toLowerCase()}',\n`;
    code += `    default_args=default_args,\n`;
    code += `    description='Scheduled execution of ${pipelineName}',\n`;
    code += `    schedule_interval='${cronExpression}',\n`;
    code += `    catchup=False,\n`;
    code += `)\n\n`;
  } else {
    // For one-time execution, set schedule_interval to None
    code += `dag = DAG(\n`;
    code += `    '${pipelineName.replace(/\s+/g, '_').toLowerCase()}_one_time',\n`;
    code += `    default_args=default_args,\n`;
    code += `    description='One-time execution of ${pipelineName}',\n`;
    code += `    schedule_interval=None,\n`;
    code += `    catchup=False,\n`;
    code += `)\n\n`;
  }
  
  // Define the task
  code += `# Define the Databricks task\n`;
  code += `run_notebook = DatabricksRunNowOperator(\n`;
  code += `    task_id='execute_databricks_notebook',\n`;
  code += `    dag=dag,\n`;
  code += `    job_id='{{job_id}}',  # Replace with your actual job ID\n`;
  code += `    notebook_params={'pipeline_name': '${pipelineName}'},\n`;
  code += `)\n\n`;
  
  // For additional tasks like notifications
  code += `# Define a notification task (example)\n`;
  code += `def send_completion_notification(**context):\n`;
  code += `    """Send a notification when the pipeline completes"""\n`;
  code += `    # Placeholder for actual notification logic\n`;
  code += `    print("Pipeline ${pipelineName} completed successfully")\n\n`;
  
  code += `notify_completion = PythonOperator(\n`;
  code += `    task_id='send_notification',\n`;
  code += `    python_callable=send_completion_notification,\n`;
  code += `    dag=dag,\n`;
  code += `)\n\n`;
  
  // Define task dependencies
  code += `# Define task dependencies\n`;
  code += `run_notebook >> notify_completion\n\n`;
  
  // Add reference to Databricks import
  code += `# To import this DAG into Databricks Workflows:\n`;
  code += `# 1. Save this code as a .py file\n`;
  code += `# 2. Import the file into your Airflow environment\n`;
  code += `# 3. Or use the Databricks Workflows UI to create a similar schedule\n`;
  
  return code;
};

/**
 * Generates a simplified code summary for the scheduler
 * @param config Schedule configuration
 * @returns Simplified code summary
 */
export const generateSchedulerSummary = (config: ScheduleConfig): string => {
  if (!config.frequency) {
    return "# Scheduler not configured";
  }
  
  let frequencyText;
  switch (config.frequency) {
    case 'once':
      frequencyText = "One-time execution";
      break;
    case 'hourly':
      frequencyText = "Every hour";
      break;
    case 'daily':
      frequencyText = "Once a day";
      break;
    case 'weekly':
      frequencyText = "Once a week";
      break;
    case 'monthly':
      frequencyText = "Once a month";
      break;
    case 'custom':
      frequencyText = config.cronExpression ? `Custom (${config.cronExpression})` : "Custom schedule";
      break;
  }
  
  return `# Schedule: ${frequencyText}\n` + 
    (config.startTime ? `# Start: ${config.startTime}\n` : '') + 
    (config.endTime ? `# End: ${config.endTime}` : '');
};
